{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SpamMailKiller.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMzSsGovHkuLwhfHM6oM85g",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RauPro/ClassificationML/blob/master/spam_mail_killer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "KbvwpeVNrSii"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import tarfile\n",
        "import urllib.request\n",
        "\n",
        "DOWNLOAD_ROOT = \"http://spamassassin.apache.org/old/publiccorpus/\"\n",
        "HAM_URL = DOWNLOAD_ROOT + \"20030228_easy_ham.tar.bz2\"\n",
        "SPAM_URL = DOWNLOAD_ROOT + \"20030228_spam.tar.bz2\"\n",
        "SPAM_PATH = os.path.join(\"datasets\", \"spam\")\n",
        "\n",
        "def fetch_spam_data(ham_url=HAM_URL, spam_url=SPAM_URL, spam_path=SPAM_PATH):\n",
        "    if not os.path.isdir(spam_path):\n",
        "        os.makedirs(spam_path)\n",
        "    for filename, url in ((\"ham.tar.bz2\", ham_url), (\"spam.tar.bz2\", spam_url)):\n",
        "        path = os.path.join(spam_path, filename)\n",
        "        if not os.path.isfile(path):\n",
        "            urllib.request.urlretrieve(url, path)\n",
        "        tar_bz2_file = tarfile.open(path)\n",
        "        tar_bz2_file.extractall(path=spam_path)\n",
        "        tar_bz2_file.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "fetch_spam_data()\n"
      ],
      "metadata": {
        "id": "1F5xB-EysLkj"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "HAM_DIR = os.path.join(SPAM_PATH, \"easy_ham\")\n",
        "SPAM_DIR = os.path.join(SPAM_PATH, \"spam\")\n",
        "ham_filenames = [name for name in sorted(os.listdir(HAM_DIR)) if len(name) > 20]\n",
        "spam_filenames = [name for name in sorted(os.listdir(SPAM_DIR)) if len(name) > 20]"
      ],
      "metadata": {
        "id": "FwOyGqdlsRMm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import email\n",
        "import email.policy\n",
        "\n",
        "def load_email(is_spam, filename, spam_path=SPAM_PATH):\n",
        "    directory = \"spam\" if is_spam else \"easy_ham\"\n",
        "    with open(os.path.join(spam_path, directory, filename), \"rb\") as f:\n",
        "        return email.parser.BytesParser(policy=email.policy.default).parse(f)"
      ],
      "metadata": {
        "id": "JKlEbhltz-Ol"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ham_emails = [load_email(is_spam=False, filename=name) for name in ham_filenames]\n",
        "spam_emails = [load_email(is_spam=True, filename=name) for name in spam_filenames]"
      ],
      "metadata": {
        "id": "W7fUlJhl0EAs"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(spam_emails[1].get_content().strip())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dsYU74-J0qJh",
        "outputId": "3bf08028-6840-42b0-9e28-a4bd070d9125"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1) Fight The Risk of Cancer!\n",
            "http://www.adclick.ws/p.cfm?o=315&s=pk007\n",
            "\n",
            "2) Slim Down - Guaranteed to lose 10-12 lbs in 30 days\n",
            "http://www.adclick.ws/p.cfm?o=249&s=pk007\n",
            "\n",
            "3) Get the Child Support You Deserve - Free Legal Advice\n",
            "http://www.adclick.ws/p.cfm?o=245&s=pk002\n",
            "\n",
            "4) Join the Web's Fastest Growing Singles Community\n",
            "http://www.adclick.ws/p.cfm?o=259&s=pk007\n",
            "\n",
            "5) Start Your Private Photo Album Online!\n",
            "http://www.adclick.ws/p.cfm?o=283&s=pk007\n",
            "\n",
            "Have a Wonderful Day,\n",
            "Offer Manager\n",
            "PrizeMama\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "If you wish to leave this list please use the link below.\n",
            "http://www.qves.com/trim/?ilug@linux.ie%7C17%7C114258\n",
            "\n",
            "\n",
            "-- \n",
            "Irish Linux Users' Group: ilug@linux.ie\n",
            "http://www.linux.ie/mailman/listinfo/ilug for (un)subscription information.\n",
            "List maintainer: listmaster@linux.ie\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_email_structure(email):\n",
        "  if isinstance(email, str):\n",
        "    return email\n",
        "  payload = email.get_payload()\n",
        "  if isinstance(payload, list):\n",
        "    return \"multipart({})\".format(\", \".join([get_email_structure(sub_email) for sub_email in payload]))\n",
        "  else:\n",
        "    return email.get_content_type()"
      ],
      "metadata": {
        "id": "e144sR6tYpoc"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "def structures_email(emails):\n",
        "  structures = Counter()\n",
        "  for email in emails:\n",
        "    structure = get_email_structure(email)\n",
        "    structures[structure] += 1 \n",
        "  return structures"
      ],
      "metadata": {
        "id": "B1qu9tKEalc-"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "structures_email(ham_emails).most_common()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "afTN8ZF8bkqs",
        "outputId": "87a093c3-a826-4a5a-df36-dac309cee0cd"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('text/plain', 2408),\n",
              " ('multipart(text/plain, application/pgp-signature)', 66),\n",
              " ('multipart(text/plain, text/html)', 8),\n",
              " ('multipart(text/plain, text/plain)', 4),\n",
              " ('multipart(text/plain)', 3),\n",
              " ('multipart(text/plain, application/octet-stream)', 2),\n",
              " ('multipart(text/plain, text/enriched)', 1),\n",
              " ('multipart(text/plain, application/ms-tnef, text/plain)', 1),\n",
              " ('multipart(multipart(text/plain, text/plain, text/plain), application/pgp-signature)',\n",
              "  1),\n",
              " ('multipart(text/plain, video/mng)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain))', 1),\n",
              " ('multipart(text/plain, application/x-pkcs7-signature)', 1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), text/rfc822-headers)',\n",
              "  1),\n",
              " ('multipart(text/plain, multipart(text/plain, text/plain), multipart(multipart(text/plain, application/x-pkcs7-signature)))',\n",
              "  1),\n",
              " ('multipart(text/plain, application/x-java-applet)', 1)]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "X = np.array(ham_emails + spam_emails, dtype=object)\n",
        "y=np.array([0] * len(ham_emails) + [1]*len(spam_emails))\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "jeRZYevZmq-F"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install html2text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JvmSIC2kqG7Q",
        "outputId": "1c3c0182-a442-4c42-ca9a-fd7da4f0b15a"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting html2text\n",
            "  Downloading html2text-2020.1.16-py3-none-any.whl (32 kB)\n",
            "Installing collected packages: html2text\n",
            "Successfully installed html2text-2020.1.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import html2text\n",
        "\n",
        "html_spam_emails = [email for email in X_train[y_train==1]\n",
        "                    if get_email_structure(email) == \"text/html\"]\n",
        "sample_html_spam = html_spam_emails[7]\n",
        "# Printing the result\n",
        "print(html2text.html2text(sample_html_spam.get_content()[:10000]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8ttkoVrqMPR",
        "outputId": "f6a7494e-64a2-4ce5-83b6-3ad38d8bff4b"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**OTC**  \n",
            "---  \n",
            "**  Newsletter**|\n",
            "\n",
            "**Discover Tomorrow's Winners  **  \n",
            "  \n",
            "| |\n",
            "\n",
            "**For Immediate Release**  \n",
            "  \n",
            "---  \n",
            "|\n",
            "\n",
            "**Cal-Bay (Stock Symbol: CBYI)**  \n",
            "Watch for analyst \"Strong Buy Recommendations\" and several advisory\n",
            "newsletters picking CBYI. CBYI has filed to be traded on the OTCBB, share\n",
            "prices historically INCREASE when companies get listed on this larger trading\n",
            "exchange. CBYI is trading around 25 cents and should skyrocket to $2.66 -\n",
            "$3.25 a share in the near future.  \n",
            "**_Put CBYI on your watch list, acquire a position TODAY._**\n",
            "\n",
            "**REASONS TO INVEST IN CBYI**\n",
            "\n",
            "* A profitable company and is on track to beat ALL earnings estimates!\n",
            "* One of the FASTEST growing distributors in environmental & safety equipment instruments.\n",
            "* Excellent management team, several EXCLUSIVE contracts. IMPRESSIVE client list including the U.S. Air Force, Anheuser-Busch, Chevron Refining and Mitsubishi Heavy Industries, GE-Energy & Environmental Research.\n",
            "\n",
            "**RAPIDLY GROWING INDUSTRY**  \n",
            "Industry revenues exceed $900 million, estimates indicate that there could be\n",
            "as much as $25 billion from \"smell technology\" by the end of 2003.\n",
            "\n",
            "**!!!!!CONGRATULATIONS!!!!!**  \n",
            "Our last recommendation to buy ORBT at $1.29 rallied and is holding steady at\n",
            "$3.50! Congratulations to all our subscribers that took advantage of this\n",
            "recommendation.\n",
            "\n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "  \n",
            "\n",
            "ALL removes HONORED. Please allow 7 days to be removed and send ALL addresses\n",
            "to:  [GoneForGood@btamail.net.cn ](mailto:goneforgood@btamail.net.cn)  \n",
            "  \n",
            "---  \n",
            "  \n",
            "---  \n",
            "|  Certain statements contained in this news release may be forward-looking\n",
            "statements within the meaning of The Private Securities Litigation Reform Act\n",
            "of 1995. These statements may be identified by such terms as \"expect\",\n",
            "\"believe\", \"may\", \"will\", and \"intend\" or similar terms. We are NOT a\n",
            "registered investment advisor or a broker dealer. This is NOT an offer to buy\n",
            "or sell securities. No recommendation that the securities of the companies\n",
            "profiled should be purchased, sold or held by individuals or entities that\n",
            "learn of the profiled companies. We were paid $27,000 in cash by a third party\n",
            "to publish this report. Investing in companies profiled is high-risk and use\n",
            "of this information is for reading purposes only. If anyone decides to act as\n",
            "an investor, then it will be that investor's sole risk. Investors are advised\n",
            "NOT to invest without the proper advisement from an attorney or a registered\n",
            "financial broker. Do not rely solely on the information presented, do\n",
            "additional independent research to form your own opinion and decision\n",
            "regarding investing in the profiled companies. Be advised that the purchase of\n",
            "such high-risk securities may result in the loss of your entire investment.\n",
            "Not intended for recipients or residents of CA,CO,CT,DE,ID,\n",
            "IL,IA,LA,MO,NV,NC,OK,OH,PA,RI,TN,VA,WA,WV,WI. Void where prohibited. The\n",
            "owners of this publication may already own free trading shares in CBYI and may\n",
            "immediately sell all or a portion of these shares into the open market at or\n",
            "about the time this report is published. Factual statements are made as of the\n",
            "date stated and are subject to change without notice.  \n",
            "Copyright c 2001\n",
            "\n",
            "* * *  \n",
            "  \n",
            "---  \n",
            "|\n",
            "\n",
            "≡\n",
            "\n",
            "|  OTC|\n",
            "\n",
            "≡  \n",
            "  \n",
            "---|---|---  \n",
            "***\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install nltk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Lk1Pa5oGrqVX",
        "outputId": "77d8faf2-7664-4045-8fa2-b99ce35927c0"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk) (1.15.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "stemmer = nltk.PorterStemmer()\n",
        "for word in (\"Computations\", \"Computation\", \"Computing\", \"Computed\", \"Compute\", \"Compulsive\"):\n",
        "  print(word, \"=>\", stemmer.stem(word))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e3gfAi5OyK8W",
        "outputId": "f66da8de-fe04-4fb7-b8e4-67fc27da6417"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Computations => comput\n",
            "Computation => comput\n",
            "Computing => comput\n",
            "Computed => comput\n",
            "Compute => comput\n",
            "Compulsive => compuls\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pip install -q -U urlextract"
      ],
      "metadata": {
        "id": "szbO7CLO2ETs"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import urlextract # may require an Internet connection to download root domain names\n",
        "url_extractor = urlextract.URLExtract()\n",
        "print(url_extractor.find_urls(\"Will it detect github.com and https://youtu.be/7Pq-S557XQU?t=3m32s\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKWk060V2KrD",
        "outputId": "edd36f99-2035-46fe-e026-aaf92b4c94e7"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['github.com', 'https://youtu.be/7Pq-S557XQU?t=3m32s']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def email_to_text(email):\n",
        "    html = None\n",
        "    for part in email.walk():\n",
        "        ctype = part.get_content_type()\n",
        "        if not ctype in (\"text/plain\", \"text/html\"):\n",
        "            continue\n",
        "        try:\n",
        "            content = part.get_content()\n",
        "        except: # in case of encoding issues\n",
        "            content = str(part.get_payload())\n",
        "        if ctype == \"text/plain\":\n",
        "            return content\n",
        "        else:\n",
        "            html = content\n",
        "    if html:\n",
        "        return html2text.html2text(html)"
      ],
      "metadata": {
        "id": "lfpb3fvAwNgo"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, TransformerMixin\n",
        "import re\n",
        "class EmailToWordCounterTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, strip_headers = True, lower_case = True, remove_punctuation= True,\n",
        "               replace_urls = True, replace_numbers=True, stemming = True):\n",
        "    self.strip_headers = strip_headers\n",
        "    self.lower_case = lower_case\n",
        "    self.remove_punctuation = remove_punctuation\n",
        "    self.replace_urls =  replace_urls\n",
        "    self.replace_numbers = replace_numbers\n",
        "    self.stemming = stemming\n",
        "  def fit(self,  X, y=None):\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    X_transformed = []\n",
        "    for email in X:\n",
        "        text = email_to_text(email) or \"\"\n",
        "        if self.lower_case:\n",
        "            text = text.lower()\n",
        "        if self.replace_urls and url_extractor is not None:\n",
        "            urls = list(set(url_extractor.find_urls(text)))\n",
        "            urls.sort(key=lambda url: len(url), reverse=True)\n",
        "            for url in urls:\n",
        "                text = text.replace(url, \" URL \")\n",
        "        if self.replace_numbers:\n",
        "            text = re.sub(r'\\d+(?:\\.\\d*)?(?:[eE][+-]?\\d+)?', 'NUMBER', text)\n",
        "        if self.remove_punctuation:\n",
        "            text = re.sub(r'\\W+', ' ', text, flags=re.M)\n",
        "        word_counts = Counter(text.split())\n",
        "        if self.stemming and stemmer is not None:\n",
        "            stemmed_word_counts = Counter()\n",
        "            for word, count in word_counts.items():\n",
        "                stemmed_word = stemmer.stem(word)\n",
        "                stemmed_word_counts[stemmed_word] += count\n",
        "            word_counts = stemmed_word_counts\n",
        "        X_transformed.append(word_counts)\n",
        "    return np.array(X_transformed)"
      ],
      "metadata": {
        "id": "H_1HRQ4E5xV1"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-px7nvyuBcI",
        "outputId": "09f10484-f3e4-47d7-db2e-00ec73c6db41"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([<email.message.EmailMessage object at 0x7f4f9d13c350>,\n",
              "       <email.message.EmailMessage object at 0x7f4f9e20ed10>,\n",
              "       <email.message.EmailMessage object at 0x7f4f9d507290>],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_few = X_train[:3]\n",
        "X_few_wordcounts = EmailToWordCounterTransformer().fit_transform(X_few)\n",
        "X_few_wordcounts"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mf28rIeg-YqP",
        "outputId": "5f5959f7-7e4d-4752-f6e4-7279b1ec018c"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([Counter({'chuck': 1, 'murcko': 1, 'wrote': 1, 'stuff': 1, 'yawn': 1, 'r': 1}),\n",
              "       Counter({'the': 11, 'of': 9, 'and': 8, 'all': 3, 'christian': 3, 'to': 3, 'by': 3, 'jefferson': 2, 'i': 2, 'have': 2, 'superstit': 2, 'one': 2, 'on': 2, 'been': 2, 'ha': 2, 'half': 2, 'rogueri': 2, 'teach': 2, 'jesu': 2, 'some': 1, 'interest': 1, 'quot': 1, 'url': 1, 'thoma': 1, 'examin': 1, 'known': 1, 'word': 1, 'do': 1, 'not': 1, 'find': 1, 'in': 1, 'our': 1, 'particular': 1, 'redeem': 1, 'featur': 1, 'they': 1, 'are': 1, 'alik': 1, 'found': 1, 'fabl': 1, 'mytholog': 1, 'million': 1, 'innoc': 1, 'men': 1, 'women': 1, 'children': 1, 'sinc': 1, 'introduct': 1, 'burnt': 1, 'tortur': 1, 'fine': 1, 'imprison': 1, 'what': 1, 'effect': 1, 'thi': 1, 'coercion': 1, 'make': 1, 'world': 1, 'fool': 1, 'other': 1, 'hypocrit': 1, 'support': 1, 'error': 1, 'over': 1, 'earth': 1, 'six': 1, 'histor': 1, 'american': 1, 'john': 1, 'e': 1, 'remsburg': 1, 'letter': 1, 'william': 1, 'short': 1, 'again': 1, 'becom': 1, 'most': 1, 'pervert': 1, 'system': 1, 'that': 1, 'ever': 1, 'shone': 1, 'man': 1, 'absurd': 1, 'untruth': 1, 'were': 1, 'perpetr': 1, 'upon': 1, 'a': 1, 'larg': 1, 'band': 1, 'dupe': 1, 'import': 1, 'led': 1, 'paul': 1, 'first': 1, 'great': 1, 'corrupt': 1}),\n",
              "       Counter({'url': 4, 's': 3, 'group': 3, 'to': 3, 'in': 2, 'forteana': 2, 'martin': 2, 'an': 2, 'and': 2, 'we': 2, 'is': 2, 'yahoo': 2, 'unsubscrib': 2, 'y': 1, 'adamson': 1, 'wrote': 1, 'for': 1, 'altern': 1, 'rather': 1, 'more': 1, 'factual': 1, 'base': 1, 'rundown': 1, 'on': 1, 'hamza': 1, 'career': 1, 'includ': 1, 'hi': 1, 'belief': 1, 'that': 1, 'all': 1, 'non': 1, 'muslim': 1, 'yemen': 1, 'should': 1, 'be': 1, 'murder': 1, 'outright': 1, 'know': 1, 'how': 1, 'unbias': 1, 'memri': 1, 'don': 1, 't': 1, 'html': 1, 'rob': 1, 'sponsor': 1, 'number': 1, 'dvd': 1, 'free': 1, 'p': 1, 'join': 1, 'now': 1, 'from': 1, 'thi': 1, 'send': 1, 'email': 1, 'egroup': 1, 'com': 1, 'your': 1, 'use': 1, 'of': 1, 'subject': 1})],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.sparse import csr_matrix\n",
        "class WordCounterToVectorTransformer(BaseEstimator, TransformerMixin):\n",
        "  def __init__(self, vocabulary_size = 1000):\n",
        "    self.vocabulary_size = vocabulary_size\n",
        "  def fit(self, X, y=None):\n",
        "    total_count = Counter()\n",
        "    for word_count in X:\n",
        "      for word, count in word_count.items():\n",
        "        total_count[word]+=min(count, 10)\n",
        "    most_common = total_count.most_common()[:self.vocabulary_size]\n",
        "    self.vocabulary_ = {word: index + 1 for index, (word, count) in enumerate(most_common)}\n",
        "    return self\n",
        "  def transform(self, X, y=None):\n",
        "    rows = []\n",
        "    cols = []\n",
        "    data = []\n",
        "    for row, word_count in enumerate(X):\n",
        "      for word, count in word_count.items():\n",
        "        rows.append(row)\n",
        "        cols.append(self.vocabulary_.get(word, 0))\n",
        "        data.append(count)\n",
        "    return csr_matrix((data, (rows, cols)), shape=(len(X), self.vocabulary_size + 1))"
      ],
      "metadata": {
        "id": "yQum0Ekm24kT"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_transformer = WordCounterToVectorTransformer(vocabulary_size = 10)\n",
        "X_few_vectors = vocab_transformer.fit_transform(X_few_wordcounts)\n",
        "X_few_vectors"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g41qyMAD5NKd",
        "outputId": "dcdf7d24-b23a-4615-8cb5-0a79b18c6e9c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<3x11 sparse matrix of type '<class 'numpy.longlong'>'\n",
              "\twith 20 stored elements in Compressed Sparse Row format>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_few_vectors.toarray()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CV76pbLI52AV",
        "outputId": "5011b104-b11f-4a32-daa5-72a14ee27c7d"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "       [99, 11,  9,  8,  3,  1,  3,  1,  3,  2,  3],\n",
              "       [67,  0,  1,  2,  3,  4,  1,  2,  0,  1,  0]], dtype=int64)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "preprocess_pipeline = Pipeline([\n",
        "  (\"email_to_wordcount\", EmailToWordCounterTransformer()),\n",
        "  (\"wordcount_to_vector\", WordCounterToVectorTransformer())\n",
        "])\n",
        "\n",
        "X_train_transformed = preprocess_pipeline.fit_transform(X_train)"
      ],
      "metadata": {
        "id": "5wr23Meg58bZ"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "log_clf = LogisticRegression(max_iter=1000, random_state=42)\n",
        "score = cross_val_score(log_clf, X_train_transformed, y_train, cv=3, verbose=3)\n",
        "score.mean()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rSkM4Gbr_Cdj",
        "outputId": "917ff567-ebf2-48db-fc66-3752dd8d62b4"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................ score: (test=0.983) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................ score: (test=0.981) total time=   0.3s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.6s remaining:    0.0s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[CV] END ................................ score: (test=0.991) total time=   0.4s\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.9s finished\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.985"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "X_test_transformed = preprocess_pipeline.transform(X_test)\n",
        "log_clf.fit(X_train_transformed, y_train)\n",
        "y_pred = log_clf.predict(X_test_transformed)\n",
        "print(\"Precision: {:.2f}%\".format(100 * precision_score(y_test, y_pred)))\n",
        "print(\"Recall: {:.2f}%\".format(100 * recall_score(y_test, y_pred)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nAeXlv_vALOl",
        "outputId": "6308313e-3db4-4cb7-d38b-74e6e026fd48"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 94.90%\n",
            "Recall: 97.89%\n"
          ]
        }
      ]
    }
  ]
}